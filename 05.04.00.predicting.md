### Predicting Image Data

Suppose we are part way through decoding an image and have decoded the pixels
shown below.

| 160     | 160     | 160     | 200    | 200     |
|:-------:|:-------:|:-------:|:------:|:-------:|
| 160     | ?       | ?       | ?      | ?       |
| 160     | ?       | ?       | ?      | ?       |
| 160     | ?       | ?       | ?      | ?       |
| 160     | ?       | ?       | ?      | ?       |
{:.xyhead}

The green cells represent pixels that we have already decoded, while the
question marks represent a 4 by 4 block of pixels that we are about to decode.

It seems natural to predict that some of the missing pixels on the left are at
least close to the value 160 even before we have seen them, while some of the
ones on the right are probably close to 200. However, it is quite possible that
the image looks like:

| 160     | 160     | 160     | 200    | 200     |
|:-------:|:-------:|:-------:|:------:|:-------:|
| 160     | 160     | 160     | 200    | 200     |
| 160     | 160     | 160     | 200    | 200     |
| 160     | 160     | 160     | 200    | 200     |
| 160     | 160     | 160     | 200    | 200     |
{:.xyhead}

or like

| 160     | 160     | 160     | 200    | 200     |
|:-------:|:-------:|:-------:|:------:|:-------:|
| 160     | 160     | 160     | 200    | 200     |
| 160     | 160     | 160     | 160    | 200     |
| 160     | 160     | 160     | 160    | 160     |
| 160     | 160     | 160     | 160    | 160     |
{:.xyhead}

AV1 contains what is called an intra mode that specifies a direction such as
vertical for the first case, or 45 degrees for the second case. When decoding a
block the decoder first reads the intra mode, and uses that to filter already
decoded pixels from the current frame to form a prediction for the contents of
the block. This is known as intra prediction and this method is called decoding
an **intra block**.

Of course, the actual content of our source image data is unlikely to be
exactly the same as the prediction.

Suppose the actual contents are:

|         |         |        |         |
|:-------:|:-------:|:------:|:-------:|
| 160     | 160     | 200    | 200     |
| 160     | 160     | 200    | 200     |
| 170     | 170     | 210    | 210     |
| 170     | 170     | 210    | 210     |
{:.nohead}

Consider the **residual** block. This is defined to be the difference between
the prediction (assume we have been instructed to use vertical prediction) and
the source image:

|         |         |        |         |
|:-------:|:-------:|:------:|:-------:|
| 0       | 0       | 0      | 0       |
| 0       | 0       | 0      | 0       |
| 10      | 10      | 10     | 10      |
| 10      | 10      | 10     | 10      |
{:.nohead}

The residual only contains small numbers, so is cheaper to represent than the original contents.

In AV1 all blocks are represented by some information specifying how to predict
the contents of the block (in this case the intra mode), plus transform
coefficients of the residual block. The decoder works by first computing the
prediction, and then inverse transforming the transform coefficients and adding
the result (the residual) to this prediction.

This process is followed even for the first blocks in the video where we do not
have any decoded pixels. In these cases the decoder pretends that it has
decoded pixels with a fixed value for the off-screen locations.
