### 5.2 Compressing image data

Suppose we have some 8-bit image data to compress and we zoom right into the
image until we see the individual pixels in a 4x4 grid - for the moment we
ignore color so each pixel is represented a single value from 0 (black) to 255
(white):

|         |         |         |         |
|:-------:|:-------:|:-------:|:-------:|
| 162     | 160     | 160     | 158     |
| 161     | 160     | 161     | 160     |
| 159     | 161     | 160     | 159     |
| 160     | 160     | 162     | 160     |
{:.nohead}

We have sixteen 8 bit numbers here which need 16*8=128 bits to store in a raw
format. However, this part of the image is so flat that we could probably
represent it as a flat area with a single value of 160 without an observer
noticing any difference. This would only need 8 bits. Similarly, suppose we had
an area that looked like this:

|         |         |         |         |
|:-------:|:-------:|:-------:|:-------:|
| 10      | 20      | 30      | 40      |
| 10      | 20      | 30      | 40      |
| 10      | 20      | 30      | 40      |
| 10      | 20      | 30      | 40      |
{:.nohead}

In this case the image gradually increases from left to right so if we had some
way of specifying the slope we could represent all 16 values with fewer bits.

AV1 approaches this is by means of a reversible **transform** that adjusts the
numbers to try and make most numbers small and a few numbers large. The essence
of the approach is to take two numbers (e.g. 162 and 160) and transform these
into the sum of the numbers, and the difference between the numbers
(162+160=322 and 162-160=2). If the decoder is given the 322 and 2 it can
reconstruct the original numbers by computing the sum and difference divided
by two (322+2)/2 = 162 and (322-2)/2 = 160. The full transform takes the sum
and differences of pairs of pixels, and performs further similar operations on
both the rows and the columns.

Overall this results in a transform that takes the 16 original pixels into 16
transformed values. The transformed values are still in a square grid, but now
the axes represent horizontal and vertical frequency. This means that if the
image is flat the transform will have just a single non-zero coefficient in the
top left (called the DC coefficient).

This transform is useful because we can compact a block of similar pixel values
into a smaller number of non-zero transform coefficients in the frequency
domain, so that the transformed coefficients can typically be represented by
fewer bits than the original.
